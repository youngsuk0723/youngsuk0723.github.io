# jemdoc: menu{MENU}{research.html}
= Research
My research interest lies in optimization, machine learning, and control. With these combinations, I develop methods related to modelings and algorithms in pursuit that AI problems can be solved with scalable and robust methods with theoretical guarantees.\n

Reinforcement Learning/Control
- Linear Quadratic Regulator for Resource-Efficient Cloud Services. Y. Park, K. Mahadik, R. Rossi, G. Wu, H. Zhao, accepted to ACM Symposium on Cloud Computing Poster Session, 2019.
#- [http://www.stanford.edu/~youngsuk/papers/LQR_Cloud.pdf Linear Quadratic Regulator for Resource-Efficient Cloud Services.] Y. Park, K. Mahadik, R. Rossi, G. Wu, H. Zhao, accepted to ACM Symposium on Cloud Computing Poster Session.
- Structured Policy Iteration for Linear Quadratic Regulator. in preparation.
- Optimal Operation of a Plug-in Hybrid Vehicle with Battery Thermal and Degradation Model. submitted to American Control Conference (ACC).
- Convergent Actor-Critic under Off-policy and Function Approximation.  \[[http://www.stanford.edu/~youngsuk/papers/gac_poster.pdf Slides]\].

Optimization
- [https://arxiv.org/abs/1810.11167 Linear Convergence of Cyclic SAGA.] Y. Park, E. K. Ryu. accepted to Optimization Letter, 2019.
- [http://www.stanford.edu/~youngsuk/papers/nips_vmpg.pdf Variable Metric Proximal Gradient Method with Diagonal Barzilai-Borwein Stepsize.] Y. Park, S. Dhar, M. Shah, S. Boyd. / NIPS Workshop, Optimization for Machine Learning/, 2017.

Machine Learning/Graphical Model 
- [http://www.stanford.edu/~youngsuk/papers/TVGL.pdf Network Inference via the Time-Varying Graphical Lasso.] D. Hallac, Y. Park, S. Boyd, J. Leskovec. /ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD)/, 2017 \[[https://github.com/davidhallac/TVGL Github]\]
- [http://stanford.edu/~boyd/papers/pairwise_exp_struct.html Learning the Network Structure of Heterogeneous Data via Pairwise Exponential Markov Random Fields.] Y. Park, D. Hallac, S. Boyd, J. Leskovec. /International Conference on Artificial Intelligence and Statistics (AISTATS)/, 2017 \[[http://www.stanford.edu/~youngsuk/papers/AISTATS_PE-MRFs_Proof.pdf Supplementary Material]\] \[[https://github.com/youngsuk0723/PE-MRF-Code Github]\]

Information Theory
- Universal Loseless Compression: Context Tree Weighting. \[[http://www.stanford.edu/~youngsuk/papers/slide_universal_compression.pdf Slides]\]
- Hypercontractivity, Maximal Correlation, and Non-cooperative Simulation. \[[http://www.stanford.edu/~youngsuk/papers/slide_measure_correlation.pdf Slides], [http://www.stanford.edu/~youngsuk/papers/report_measure_correlation.pdf Report]\]
- Successive Lossy Compression for Laplacian Source. \[[http://www.stanford.edu/~youngsuk/papers/slide_lossycompression.pdf Slides], [http://www.stanford.edu/~youngsuk/papers/report_lossycompression.pdf Report]\]
